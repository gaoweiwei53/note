# 1. Hadoop
## 1. hadoop常用端口号？
hadoop3.x 
- HDFS NameNode 内部通常端口：8020/9000/9820
- HDFS NameNode 对用户的查询端口：9870
- Yarn查看任务运行情况的：8088
- 历史服务器：19888

## 2. HDFS文件块大小？
128M
## 3. HDFS的读写流程（面试重点）？

## 4. MapReduce的工作流程

## 5. Yarn的工作机制（面试题）

## 6. HDFS安全模式
安全模式是hadoop的一种保护机制，用于保证集群中的数据块的安全性。当集群启动的时候，会首先进入安全模式。当系统处于安全模式时会检查数据块的完整性。检查副本率小于设置的则会复制block到其他datanode中。
## 7. 什么是命名空间 namespace
hdfs文件系统里的文件夹、文件、文件结构(文件系统树)一起构成了namespace，metadata指的是这些文件夹或文件的属性。
# 2. Kafka
## 1. Partition 和 Replica
Producer产生的消息发布到topic里，Event会按照相同的**event key**追加到这个Topic的其中同一个Partition上。每一个Partition都会有若个Replica，这些Replica分布在不同的broker上，且每个broker至多只能有一个同一个Partition对应的Replica。所以一个topic的replica的数量不会多于broker的数量。

一个Partition的所有的Replica中，有一个是leader，其他都是follower。读写消息的过程只通过leader完成。

客户端可以控制向哪个partiton发送消息。默认的是随机发送，这样可以负载平衡。用户也可以自定义分区函数，例如使相同的user id的消息hash到同一个partition.
## 2. Pull or Push
Producer *Push* 到broker，然后由consumer 从broker里 *pull* 消息 
### Push方式
优点：Consumer可以以最大速率消费数据。  
缺点：broker不知道下游的消费者是否能够立即消费，它要决定是立即发送消息还是积累数据等待一段时间再发送。
### Pull方式
优点：consumer可以自定义消费速率; 能更好地以批方式拉取数据而不会导致延迟  
缺点：当broker没有消息时，consumer会等待。解决办法：设置等待的时间

## 3. kafka如何保证一致性语义？
### 3.1 消息传送保证
- At most once：最多发送一次，丢失不重发，会丢失数据。
- At least once：只发送一次，丢失会重发，所以永远不会丢失数据。
- Exactly once：每个数据只会且会被发送一次。
> 对于kafka包括*发布消息时地一致性保证*和*消费消息时的一致性保证*
## 3.2 发布消息时地一致性保证
当发布消息时，有一个“Committed”到日志里的概念。当消息是Committed时，只要它所在的broker存活就不会丢失。

在0.11.0.0版本之前，producer发布消息网络发生故障时，如果producer没有收到消息被committed的回复，那么它就会重发。这样可能会导致数据重复写入。

从0.11.0.0版本开始，kafka提供了**幂等( idempotent)发送**操作，可以保证重发的消息不会被重复写入。为了实现这一点，broker为每个生产者分配一个ID，并使用生产者连同每个消息一起发送的序列号对消息进行重复数据删除。

并且从0.11.0.0版本开始，生产者支持使用类似事务的语义将消息发送到多个主题分区的能力，即要么所有消息都被成功写入，要么没有消息被成功写入。

并不是所有的情况都需要这样强有力的保证。对于延迟敏感的场景，Producer可指定它想要的持久性级别。如果生产者指定它希望等待提交的消息，例如可指定10毫秒。然而，生产者也可以指定它希望完全异步地执行发送，或者它希望只等待leader(但不一定是follower)有确认消息。
## 3.3 消费消息时的一致性
所有replica都具有具有相同偏移量的完全相同的日志。如果消费者从未崩溃，它可以将这个offset存储在内存中，但如果消费者崩溃，topic分区被另一个进程接管，新进程将需要选择一个合适的offset开始消费。它有几个处理消息和更新其offset的选择。
