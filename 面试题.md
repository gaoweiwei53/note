# 1. Hadoop
## 1. hadoop常用端口号？
hadoop3.x 
- HDFS NameNode 内部通常端口：8020/9000/9820
- HDFS NameNode 对用户的查询端口：9870
- Yarn查看任务运行情况的：8088
- 历史服务器：19888

## 2. HDFS文件块大小？
128M
## 3. HDFS的读写流程（面试重点）？

## 4. MapReduce的工作流程

## 5. Yarn的工作机制（面试题）

## 6. HDFS安全模式
安全模式是hadoop的一种保护机制，用于保证集群中的数据块的安全性。当集群启动的时候，会首先进入安全模式。当系统处于安全模式时会检查数据块的完整性。检查副本率小于设置的则会复制block到其他datanode中。
## 7. 什么是命名空间 namespace
hdfs文件系统里的文件夹、文件、文件结构(文件系统树)一起构成了namespace，metadata指的是这些文件夹或文件的属性。
# 2. Kafka
## 1. Partition 和 Replica
Producer产生的消息发布到topic里，Event会按照相同的**event key**追加到这个Topic的其中同一个Partition上。每一个Partition都会有若个Replica，这些Replica分布在不同的broker上，且每个broker至多只能有一个同一个Partition对应的Replica。所以一个topic的replica的数量不会多于broker的数量。

一个Partition的所有的Replica中，有一个是leader，其他都是follower。读写消息的过程只通过leader完成。

客户端可以控制向哪个partiton发送消息。默认的是随机发送，这样可以负载平衡。用户也可以自定义分区函数，例如使相同的user id的消息hash到同一个partition.
## 2. Pull or Push
Producer *Push* 到broker，然后由consumer 从broker里 *pull* 消息 
### Push方式
优点：Consumer可以以最大速率消费数据。  
缺点：broker不知道下游的消费者是否能够立即消费，它要决定是立即发送消息还是积累数据等待一段时间再发送。
### Pull方式
优点：consumer可以自定义消费速率; 能更好地以批方式拉取数据而不会导致延迟  
缺点：当broker没有消息时，consumer会等待。解决办法：设置等待的时间

## 3. kafka如何保证一致性语义？
### 3.1 消息传送保证
- At most once：最多发送一次，丢失不重发，会丢失数据。
- At least once：只发送一次，丢失会重发，所以永远不会丢失数据。
- Exactly once：每个数据只会且会被发送一次。
> 对于kafka包括*发布消息时地一致性保证*和*消费消息时的一致性保证*
## 3.2 发布消息时地一致性保证
当发布消息时，有一个“Committed”到日志里的概念。当消息是Committed时，只要它所在的broker存活就不会丢失。

在0.11.0.0版本之前，producer发布消息网络发生故障时，如果producer没有收到消息被committed的回复，那么它就会重发。这样可能会导致数据重复写入。

从0.11.0.0版本开始，kafka提供了**幂等( idempotent)发送**操作，可以保证重发的消息不会被重复写入。为了实现这一点，broker为每个生产者分配一个ID，并使用生产者连同每个消息一起发送的序列号对消息进行重复数据删除。

并且从0.11.0.0版本开始，生产者支持使用类似事务的语义将消息发送到多个主题分区的能力，即要么所有消息都被成功写入，要么没有消息被成功写入。

并不是所有的情况都需要这样强有力的保证。对于延迟敏感的场景，Producer可指定它想要的持久性级别。如果生产者指定它希望等待提交的消息，例如可指定10毫秒。然而，生产者也可以指定它希望完全异步地执行发送，或者它希望只等待leader(但不一定是follower)有确认消息。
## 3.3 消费消息时的一致性
所有replica都具有具有相同偏移量的完全相同的日志。如果消费者从未崩溃，它可以将这个offset存储在内存中，但如果消费者崩溃，topic分区被另一个进程接管，新进程将需要选择一个合适的offset开始消费。它有几个处理消息和更新其offset的选择。

当写入到外部系统时，需要协调consumer的位置和输出。经典的做法是**两段提交**，然而并不是所有的外部系统都支持两端提交。另一种简单的做法是让consumer把它的offset存储在与输出地方的相同位置。例如将数据和读取到的offset一起导入到HDFS中，这样就可以保证数据和偏移量都被更新或者都不更新。

## 3.4 副本 
 leader维护着"in sync"列表，当有follower崩了或者消息落后leader很多时，leader就会将这个follower从ISA中移除。现在可以更精确地定义，当该分区的所有同步副本都将消息写到到日志中时，该消息被认为已提交。只有已提交的消息才会分发给consumer。另一方面，生产者可以选择等待消息提交或不提交，这取决于他们在延迟和持久性之间的权衡。该选择由producer使用的acks设置控制。注意，topic有一个`minmum number` 的同步副本设置，当producer请求确认: 消息已经被写入ISA中所有的同步副本时，会检查该设置。如果生产者请求的是一个不那么严格的确认，即使同步中的副本数量低于最小值(例如，它可以低到只有leader)，那么消息可以被提交和消费，
## 3.5 Replicated Log
日志复制算法必须提供的基本保证是，如果我们告诉客户端一条消息已经提交，并且leader不可用了，我们选举的新leader也必须有这个消息。当有多个follower时，就要权衡。对于这个权衡，一个常用的方法就是对**提交决定**和**leader选举**都是用多票方法。这种方法族里包括很多算法，例如ZooKeeper的**Zab**, **Raft**和 **Viewstamped Replication**. 我们所知道的与Kafka的实际实现最相似的是微软的**PacificA**.

## 3.6 Quorum
